{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a72667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3bbce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pipe-delimited text file\n",
    "df = pd.read_csv('../data/MachineLearningRating_v3.txt', sep='|')\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('../data/data.csv', index=False)\n",
    "\n",
    "print(\"Conversion completed: 'data.csv' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "# Get number of columns\n",
    "num_columns = df.shape[1]\n",
    "print(f\"Number of columns: {num_columns}\")\n",
    "\n",
    "# Get column data types\n",
    "print(\"\\nColumn data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119b4bf",
   "metadata": {},
   "source": [
    "Data Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical columns of interest\n",
    "numeric_cols = [\n",
    "    \"TotalPremium\",\n",
    "    \"TotalClaims\",\n",
    "    \"CalculatedPremiumPerTerm\",\n",
    "    \"SumInsured\",\n",
    "    \"CustomValueEstimate\",\n",
    "    \"NumberOfVehiclesInFleet\",\n",
    "    \"CapitalOutstanding\"\n",
    "]\n",
    "\n",
    "# Convert these columns to numeric, coercing errors to NaN\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Initial NaN count (before imputation)\n",
    "nan_counts_before = df[numeric_cols].isna().sum()\n",
    "print(\"Number of rows with NaN in each column (before imputation):\")\n",
    "print(nan_counts_before)\n",
    "\n",
    "# Impute CapitalOutstanding with median\n",
    "median_value = df[\"CapitalOutstanding\"].median()\n",
    "df[\"CapitalOutstanding\"].fillna(median_value, inplace=True)\n",
    "\n",
    "# Recalculate NaN count (after imputation)\n",
    "nan_counts_after = df[numeric_cols].isna().sum()\n",
    "print(\"\\nNumber of rows with NaN in each column (after imputing CapitalOutstanding):\")\n",
    "print(nan_counts_after)\n",
    "\n",
    "# Count rows with at least one NaN in numeric columns\n",
    "num_nan_rows = df[df[numeric_cols].isna().any(axis=1)].shape[0]\n",
    "print(f\"\\nNumber of rows with at least one NaN in numeric columns: {num_nan_rows}\")\n",
    "\n",
    "# Optional: Check how many columns in the entire DataFrame still have NaNs\n",
    "cols_with_nan = df.isna().sum()\n",
    "print(\"\\nTotal columns still containing NaNs in the entire DataFrame:\")\n",
    "print(cols_with_nan[cols_with_nan > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17927da",
   "metadata": {},
   "source": [
    "handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b42402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns with Extremely High Missingness & Low Predictive Value\n",
    "df.drop(columns=[\n",
    "    \"CustomValueEstimate\", \"NumberOfVehiclesInFleet\",\n",
    "    \"WrittenOff\", \"Rebuilt\", \"Converted\", \"CrossBorder\"\n",
    "], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345787e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Variables — Impute with \"Unknown\" or Mode\n",
    "categorical_cols = [\"Bank\", \"AccountType\", \"MaritalStatus\", \"Gender\", \n",
    "                    \"VehicleType\", \"make\", \"Model\", \"bodytype\", \"NewVehicle\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical Variables — Impute with Median\n",
    "num_cols = [\"mmcode\", \"Cylinders\", \"cubiccapacity\", \"kilowatts\", \"NumberOfDoors\"]\n",
    "\n",
    "for col in num_cols:\n",
    "    median_val = df[col].median()\n",
    "    df[col].fillna(median_val, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b39ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of columns\n",
    "num_columns = df.shape[1]\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Check how many columns in the entire DataFrame still have NaNs\n",
    "cols_with_nan_after_handling = df.isna().sum()\n",
    "print(\"\\nTotal columns still containing NaNs in the entire DataFrame:\")\n",
    "print(cols_with_nan_after_handling[cols_with_nan_after_handling > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343489fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute basic descriptive statistics\n",
    "descriptive_stats = df[numeric_cols].describe().T  # Transpose for better readability\n",
    "\n",
    "# Add variance and coefficient of variation (CV = std / mean)\n",
    "descriptive_stats[\"variance\"] = df[numeric_cols].var()\n",
    "descriptive_stats[\"cv\"] = descriptive_stats[\"std\"] / descriptive_stats[\"mean\"]\n",
    "\n",
    "# Display results\n",
    "print(descriptive_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b34d4",
   "metadata": {},
   "source": [
    "Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d93ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types of each column\n",
    "print(\"Column Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Summary of column types\n",
    "print(\"\\nSummary of Column Types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Identify columns by inferred type\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "bool_cols = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "# Display lists\n",
    "print(f\"\\nCategorical Columns ({len(categorical_cols)}):\\n{categorical_cols}\")\n",
    "print(f\"\\nNumerical Columns ({len(numerical_cols)}):\\n{numerical_cols}\")\n",
    "print(f\"\\nBoolean Columns ({len(bool_cols)}):\\n{bool_cols}\")\n",
    "\n",
    "# Check for possible datetime fields\n",
    "print(\"\\nChecking object columns for potential date fields:\")\n",
    "for col in categorical_cols:\n",
    "    try:\n",
    "        parsed = pd.to_datetime(df[col], errors='raise')\n",
    "        print(f\"✅ '{col}' can be converted to datetime.\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of plots per row\n",
    "plots_per_row = 3\n",
    "num_cols = len(numerical_cols)\n",
    "num_rows = math.ceil(num_cols / plots_per_row)\n",
    "\n",
    "# Set figure size based on number of rows/columns\n",
    "plt.figure(figsize=(plots_per_row * 6, num_rows * 4))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot histograms in a grid layout\n",
    "for idx, col in enumerate(numerical_cols, start=1):\n",
    "    plt.subplot(num_rows, plots_per_row, idx)\n",
    "    sns.histplot(df[col].dropna(), kde=True, bins=30, color='skyblue')\n",
    "    plt.title(f\"{col}\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6713861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# --- 2. Bar Charts for Categorical Variables ---\n",
    "for col in categorical_cols:\n",
    "    plt.figure()\n",
    "    top_values = df[col].value_counts().nlargest(10)\n",
    "    sns.barplot(x=top_values.index, y=top_values.values)\n",
    "    plt.title(f\"Top 10 Categories in '{col}'\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 3. Bar Charts for Boolean Variables ---\n",
    "for col in bool_cols:\n",
    "    plt.figure()\n",
    "    sns.countplot(x=df[col])\n",
    "    plt.title(f\"Distribution of Boolean Feature: '{col}'\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a3cf5",
   "metadata": {},
   "source": [
    "Bivariate / Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdfb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert 'TransactionMonth' to datetime\n",
    "df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'], errors='coerce')\n",
    "\n",
    "# 2. Group by PostalCode and Month, then aggregate\n",
    "grouped = df.groupby(['PostalCode', pd.Grouper(key='TransactionMonth', freq='M')])[\n",
    "    ['TotalPremium', 'TotalClaims']\n",
    "].sum().reset_index()\n",
    "\n",
    "# 3. Scatter Plot: TotalPremium vs TotalClaims\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=grouped, x='TotalPremium', y='TotalClaims', hue='PostalCode', palette='tab20', legend=False)\n",
    "plt.title(\"TotalPremium vs TotalClaims by PostalCode per Month\")\n",
    "plt.xlabel(\"Total Premium (monthly, per Zip)\")\n",
    "plt.ylabel(\"Total Claims (monthly, per Zip)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Correlation Matrix: Numerical aggregates per PostalCode\n",
    "postal_corr = grouped.groupby(\"PostalCode\")[['TotalPremium', 'TotalClaims']].sum().corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(postal_corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix: TotalPremium & TotalClaims (Aggregated by ZipCode)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbeabd",
   "metadata": {},
   "source": [
    "Data Comparison Over Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba6ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# --- 1. Compare CoverType distribution by Province ---\n",
    "cover_geo = df.groupby(['Province', 'CoverType']).size().unstack().fillna(0)\n",
    "\n",
    "cover_geo.plot(kind='bar', stacked=True)\n",
    "plt.title(\"CoverType Distribution by Province\")\n",
    "plt.ylabel(\"Number of Policies\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 2. Compare average TotalPremium by Province ---\n",
    "premium_geo = df.groupby('Province')['TotalPremium'].mean().sort_values()\n",
    "\n",
    "premium_geo.plot(kind='bar', color='teal')\n",
    "plt.title(\"Average Total Premium by Province\")\n",
    "plt.ylabel(\"Average Premium\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 3. Compare most popular Auto Make by Province (Top 5 Makes only) ---\n",
    "top_makes = df['make'].value_counts().nlargest(5).index.tolist()\n",
    "df_top_makes = df[df['make'].isin(top_makes)]\n",
    "\n",
    "make_geo = df_top_makes.groupby(['Province', 'make']).size().unstack().fillna(0)\n",
    "\n",
    "make_geo.plot(kind='bar', stacked=True)\n",
    "plt.title(\"Top 5 Auto Makes Distribution by Province\")\n",
    "plt.ylabel(\"Number of Vehicles\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
